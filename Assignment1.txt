Data Analytics 
SESSION 6: Visualization & Plotting 
Assignment 1 


1. Import the Titanic Dataset from the following link: 
https://drive.google.com/file/d/1JTJCjdGuUxzKXYlwOavwovB01k6FWg3r/view?ts=5b42ea10 
Perform the below operations: 

a. Pre-process the passenger names to come up with a list of 
titles that represent families and represent using appropriate visualization graph. 

Answer:

library(reshape) 
library(caret)
d <- train 
d.nrow<-seq(1, nrow(d)) # save the number of rows in the train dataset 
d.miss <- melt(apply(d[, -2], 2, function(x) 
sum(is.na(x) | x==""))) 
cbind(row.names(d.miss)[d.miss$value>0], d.miss[d.miss$value>0,])

 [,1]       [,2] 


[1,] "Age" "177" [2,] "Cabin" "687" [3,] "Embarked" "2"

#Variable "Cabin" #"Cabin" has missed about 80% values. We will not use this variable.

#Variable "Embarked" #Update missing Embarked value with the most common value:

#table(d$Embarked) #Variable "Price" #Some Fare values contains sum for tickets were purchased in groups. Introduce a new variable "Price" that will be Fare per person.

d$Fare[which(is.na(d$Fare))] <- 0 # Update missing Fare value with 0.
calculate Ticket Price (Fare per person)

ticket.count <- aggregate(d$Ticket, by=list(d$Ticket), function(x) 
sum( !is.na(x) )) 
d$Price<-apply(d, 1, function(x) as.numeric(x["Fare"]) / ticket.count[which(ticket.count[, 1] == x["Ticket"]), 2])

    Capt          Col          Don           Dr     Jonkheer         Lady 
       1            2            1            7            1            1 
   Major       Master         Miss         Mlle          Mme           Mr 
       2           40          182            2            1          517 
     Mrs           Ms          Rev          Sir the Countess 
     125            1            6            1            1 

#Price related to passenger class. Missig price values (price=0) we can update with median price per passenger class:

pclass.price<-aggregate(d$Price, by = list(d$Pclass), FUN = function(x) median(x, na.rm = T)) d[which(d$Price==0), "Price"] <- apply(d[which(d$Price==0), ] , 1, function(x) pclass.price[pclass.price[, 1]==x["Pclass"], 2]) 

#Variable "Title" #Extract title of each persons name to a new variable "Title" 

d$Title<-regmatches(as.character(d$Name),regexpr("\,[A-z ]{1,20}\.", as.character(d$Name))) 
d$Title<-unlist(lapply(d$Title,FUN=function(x) substr(x, 3, nchar(x)-1))) table(d$Title) 

Signif. codes: 0 ‘’ 0.001 ‘’ 0.01 ‘’ 0.05 ‘.’ 0.1 ‘ ’ 1
(Dispersion parameter for binomial family taken to be 1)

#Merge 17 different title groups to the most common 4 groups.
d$Title[which(d$Title %in% c("Mme", "Mlle"))] <- "Miss" d$Title[which(d$Title %in% c("Lady", "Ms", "the Countess", "Dona"))] <- "Mrs" d$Title[which(d$Title=="Dr" & d$Sex=="female")] <- "Mrs" d$Title[which(d$Title=="Dr" & d$Sex=="male")] <- "Mr" d$Title[which(d$Title %in% c("Capt", "Col", "Don", "Jonkheer", "Major", "Rev", "Sir"))] <- "Mr" d$Title<-as.factor(d$Title) #convert to factor variable #Variable "Age" #Update unknown age with median age for each group of title:
title.age<-aggregate(d$Age,by = list(d$Title), FUN = function(x) median(x, na.rm = T)) d[is.na(d$Age), "Age"] <- apply(d[is.na(d$Age), ] , 1, function(x) title.age[title.age[, 1]==x["Title"], 2]) #Split train and test data #We merged train and test data at the begining of preprocess. Now we will split it back to "t" and "d" Data frame variables. #Data frame "t" has no "Survival" values and will be used to predict "Survival" and submit on Kaggle. #Data frame "d" that contains train data we also split to test prediction models.
t <- d[-d.nrow, ] # test data. It has no "Survival" values. d <- d[d.nrow, ] #Train data set.seed(1234) inTrain<-createDataPartition(d$Survived, p = 0.8)[[1]] #Fitting a linear model that includes all variables. fit.8 <- glm(Survived ~ Pclass+Sex+Age+SibSp+Parch+Embarked+Title+Price+Ticket, data=d[inTrain,], family=binomial(("logit"))) 
summary(fit.8) 
#Fitting a linear model that includes 5 statistically significant variable and "Ticket" converted to a factor variable. 
fit.6.grp <- glm(Survived ~ Pclass+Age+SibSp+Parch+Title+I(Ticket>2), data=d[inTrain,], family=binomial) summary(fit.6.grp)

Call: glm(formula = Survived ~ Pclass + Sex + Age + SibSp + Parch + Embarked + Title + Price + Ticket, family = binomial(("logit")), data = d[inTrain, ])

Deviance Residuals: Min 1Q Median 3Q Max
-8.49 0.00 0.00 0.00 8.49
Signif. codes: 0 ‘’ 0.001 ‘’ 0.01 ‘’ 0.05 ‘.’ 0.1 ‘ ’ 1
(Dispersion parameter for binomial family taken to be 1)
Null deviance: 943.08 on 711 degrees of freedom Residual deviance: 576.70 on 141 degrees of freedom (1 observation deleted due to missingness) AIC: 1718.7
Number of Fisher Scoring iterations: 16

Call: glm(formula = Survived ~ Pclass + Age + SibSp + Parch + Title + I(Ticket > 2), 
family = binomial, data = d[inTrain, ])

Deviance Residuals: Min 1Q Median 3Q Max
-2.6268 -0.5138 -0.3596 0.5342 2.6923

Signif. codes: 0 ‘’ 0.001 ‘’ 0.01 ‘’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1)
Null deviance: 945.03  on 712  degrees of freedom

Residual deviance: 567.25 on 704 degrees of freedom AIC: 585.25
Number of Fisher Scoring iterations: 5

p1 <- ggplot(data=train,aes(x=Age)) + geom_histogram(aes(fill=Survived),bins = 40) + coord_flip() p2 <- ggplot(data=train,aes(x=Fare)) + geom_histogram(aes(fill=Survived),bins = 40) + coord_flip() grid.arrange(p1,p2,nrow=1) summary(train$Fare) get_legend<-function(myggplot){ tmp <- ggplot_gtable(ggplot_build(myggplot)) leg <- which(sapply(train, function(x) x$name) == "guide-box") legend <- tmp$grobs[[leg]] return(legend) } p <- lapply(X = c('Pclass','Sex','SibSp','Parch','Embarked'), FUN = function(x) ggplot(data = train)+ aes_string(x=x,fill='Survived')+ geom_bar(position="dodge")+ theme(legend.position="none"))
 summary(train$Embarked)
train.imp <- train
train.imp$Embarked[is.na(train.imp$Embarked)] <- 'S'
train.imp$title <- str_extract(pattern = '[a-zA-Z]+(?=\\.)',string = train.imp$Name)
train.imp$title <- as.factor(train.imp$title)
ggplot(train.imp,aes(x=title,y=Age))+
    geom_jitter(shape=21,alpha=.6,col='blue')+
    stat_summary(aes(y = Age,group=1), fun.y=median, colour="red", geom="point",group=1)+
    theme_bw()+
    theme(axis.text.x = element_text(angle = 45, hjust = 1),legend.position="none")+
    labs(caption='red points are median values')
train.imp$title <- as.character(train.imp$title)
train.imp$title[train.imp$title %in% c('Capt','Col','Major')] <- 'Officer'
train.imp$title[train.imp$title %in% c('Don','Dr','Rev','Sir','Jonkheer','Countess','Lady','Dona')] <- 'Royalty'
train.imp$title[train.imp$title %in% c('Mrs','Mme')] <- 'Mrs'
train.imp$title[train.imp$title %in% c('Ms','Mlle')] <- 'Miss'
train.imp$title <- as.factor(train.imp$title)
ggplot(train.imp,aes(x=title,y=Age))+
    geom_jitter(color='blue',shape=21,alpha=.7)+
    stat_summary(aes(y = Age,group=1), fun.y=median, colour="red", geom="point",group=1)+
    theme_bw()+
    theme(axis.text.x = element_text(angle = 45, hjust = 1))+
    labs(caption='red points are median values')

  age.predictors <- train.imp %>%
    dplyr::select(-Survived,-Cabin,-Ticket,-Name) %>%
    dplyr::filter(complete.cases(.))
ctrl <- trainControl(method = "repeatedcv",
                     repeats = 5)
rpartGrid <- data.frame(maxdepth = seq(2,10,1))
rpartFit_ageimputation <- train(x=age.predictors[,-3],
                      y=age.predictors$Age,
                      method='rpart2',
                      trControl = ctrl,
                      tuneGrid = rpartGrid
                      )
rpartFit_ageimputation
## CART 
## 
## 508 samples
##   7 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold, repeated 5 times) 
## Summary of sample sizes: 457, 457, 457, 457, 457, 457, ... 
## Resampling results across tuning parameters:
## 
##   maxdepth  RMSE      Rsquared   MAE     
##    2        12.02414  0.3171031  9.443687
##    3        11.30498  0.3985131  8.707856
##    4        11.42463  0.3882499  8.782511
##    5        11.27085  0.4038018  8.639549
##    6        11.39825  0.3930011  8.720958
##    7        11.43177  0.3890118  8.744528
##    8        11.47797  0.3851413  8.783542
##    9        11.48005  0.3848860  8.783870
##   10        11.48005  0.3848860  8.783870
## 
## RMSE was used to select the optimal model using the smallest value.
## The final value used for the model was maxdepth = 5.
plot(rpartFit_ageimputation)
rpart.plot::rpart.plot(rpartFit_ageimputation$finalModel, extra=101, box.palette="GnBu")
save(rpartFit_ageimputation,file = 'rpartFit_ageimputation')
missing_age <- is.na(train.imp$Age)
age.predicted <- predict(rpartFit_ageimputation, newdata = train.imp[missing_age,])
train.imp[missing_age,'Age'] <- age.predicted

train.imp %>% 
    mutate(Age_Imputed = missing_age) %>% 
    ggplot(aes(x=title,y=Age))+
    stat_summary(aes(y = Age,group=1), fun.y=median, colour="red", geom="point",group=1)+
    geom_jitter(aes(y=Age,col=Age_Imputed,shape=Age_Imputed))+
    theme_bw()+
    theme(axis.text.x = element_text(angle = 45, hjust = 1),legend.position="none")+
    labs(caption='green points are imputed values')
train.imp$child <- 0
train.imp$child[train.imp$Age<18] <- 1
train.imp$Seniors <- ifelse(train.imp$Age>60,1,0)
train.imp$TotalFam <- train.imp$SibSp + train.imp$Parch + 1
train.imp$LargeFamily <- ifelse(train.imp$TotalFam>4,1,0)
train.imp$Name <- NULL
train.imp$CabinCode <- map_chr(train$Cabin,~str_split(string = .x,pattern = '')[[1]][1])
train.imp$CabinCode[is.na(train.imp$CabinCode)] <- 'U'
train.imp$CabinCode <- as.factor(train.imp$CabinCode)

train.imp$CabinNum <- as.numeric(map_chr(train$Cabin,~str_split(string = .x,pattern = '[a-zA-Z]')[[1]][2]))
train.imp$CabinNum <- map_int(train.imp$CabinNum, ~as.integer(str_split(.x,pattern = '',simplify = T)[1][1]))
train.imp$CabinNum[is.na(train.imp$CabinNum)] <- 0

train.imp$TopDeck <- ifelse(train.imp$CabinCode %in% c('A','B'),1,0)
train.imp$MidDeck <- ifelse(train.imp$CabinCode %in% c('C','D'),1,0)
train.imp$LowerDeck <- ifelse(train.imp$TopDeck==0 & train.imp$MidDeck==0 ,1,0)

train.imp$NumberofCabins <- map_int(train$Cabin,~str_split(string = .x,pattern = ' ')[[1]] %>% length)
train.imp$Cabin <- NULL
train.imp$Ticket %>% table() %>% as.numeric() %>% table()
## .
##   1   2   3   4   5   6   7 
## 430  60  15   3   1   1   1
train.imp %>% group_by(Pclass) %>% dplyr::select(Ticket,Pclass) %>% sample_n(5)



ggplot(train,aes(y=Age,x=Pclass))+geom_boxplot(aes(fill=Survived))+theme_bw() Warning messages: 1: Continuous x aesthetic -- did you forget aes(group=...)? 2: Removed 177 rows containing non-finite values (stat_boxplot).
beanplot(Age~Survived*Pclass,side='b',train,col=list('yellow','orange'),
•	     border = c('yellow2','darkorange'),ll = 0.05,boxwex = .5,
•	
•	     main='Passenger survival by pclass and Age',xlab='Passenger Class',ylab='Age')
•	
legend('topright', fill = c('yellow','orange'), legend = c("Dead", "Survived"),bty = 'n',cex = .8)
stat_summary(aes(y = Age,group=1), fun.y=median, colour="red", geom="point",group=1)+ theme_bw()+ theme(axis.text.x = element_text(angle = 45, hjust = 1),legend.position="none")+ labs(caption='red points are median values')
CART
508 samples
7 predictor
No pre-processing
Resampling: Cross-Validated (10 fold, repeated 5 times)
Summary of sample sizes: 457, 457, 457, 457, 457, 457, ...
Resampling results across tuning parameters:
maxdepth RMSE Rsquared MAE
2 12.02414 0.3171031 9.443687
3 11.30498 0.3985131 8.707856
4 11.42463 0.3882499 8.782511
5 11.27085 0.4038018 8.639549
6 11.39825 0.3930011 8.720958
7 11.43177 0.3890118 8.744528
8 11.47797 0.3851413 8.783542
9 11.48005 0.3848860 8.783870
10 11.48005 0.3848860 8.783870
RMSE was used to select the optimal model using the smallest value.
The final value used for the model was maxdepth = 5.
plot(rpartFit_ageimputation) rpart.plot::rpart.plot(rpartFit_ageimputation$finalModel, extra=101, box.palette="GnBu") save(rpartFit_ageimputation,file = 'rpartFit_ageimputation')
Ticket Pclass 113767 1 17421 1 PC 17582 1 113510 1 13507 1 S.O.C. 14879 2 244373 2 239853 2 C.A. 31921 2 236853 2 Next 12 Previous 1-10 of 15 rows Ticket Pclass 2665 3 2691 3 A/4 48871 3 349204 3 349248 3






b. Represent the proportion of people survived by family size 
using a graph. 

Answer:

get_legend<-function(myggplot){ tmp <- ggplot_gtable(ggplot_build(myggplot)) leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box") legend <- tmp$grobs[[leg]] return(legend) }p <- lapply(X = c('Pclass','Sex','SibSp','Parch','Embarked'), FUN = function(x) ggplot(data = train)+ aes_string(x=x,fill='Survived')+ geom_bar(position="dodge")+ theme(legend.position="none")) legend <- get_legend(ggplot(data = train,aes(x=Pclass,fill=Survived))+geom_bar()) grid.arrange(p[[1]],p[[2]],p[[3]],p[[4]],p[[5]], legend,layout_matrix = cbind(c(1,2,3), c(4,5,3), c(6,6,6)), widths=c(3,3,1))
ggplot(train,aes(y=Age,x=Pclass))+geom_boxplot(aes(fill=Survived))+theme_bw()
beanplot(Age~Survived*Pclass,side='b',train,col=list('yellow','orange'),
•	     border = c('yellow2','darkorange'),ll = 0.05,boxwex = .5,
•	
•	     main='Passenger survival by pclass and Age',xlab='Passenger Class',ylab='Age')
•	




c. Impute the missing values in Age variable using Mice library, create two different graphs showing Age distribution before and after imputation 

Answer:

summary(training) PassengerId Survived Pclass Name Sex

Min. : 1.0 Min. :0.0000 Min. :1.000 Length:891 Length:891
1st Qu.:223.5 1st Qu.:0.0000 1st Qu.:2.000 Class :character Class :character
Median :446.0 Median :0.0000 Median :3.000 Mode :character Mode :character
Mean :446.0 Mean :0.3838 Mean :2.309
3rd Qu.:668.5 3rd Qu.:1.0000 3rd Qu.:3.000
Max. :891.0 Max. :1.0000 Max. :3.000
  Age            SibSp           Parch           Ticket               Fare       
Min. : 0.42 Min. :0.000 Min. :0.0000 Length:891 Min. : 0.00
1st Qu.:20.12 1st Qu.:0.000 1st Qu.:0.0000 Class :character 1st Qu.: 7.91
Median :28.00 Median :0.000 Median :0.0000 Mode :character Median : 14.45
Mean :29.70 Mean :0.523 Mean :0.3816 Mean : 32.20
3rd Qu.:38.00 3rd Qu.:1.000 3rd Qu.:0.0000 3rd Qu.: 31.00
Max. :80.00 Max. :8.000 Max. :6.0000 Max. :512.33
NA's :177

Cabin Embarked
Length:891 Length:891
Class :character Class :character
Mode :character Mode :character


dim(training) [1] 891 12

str(training) 

Classes ‘tbl_df’, ‘tbl’ and 'data.frame': 891 obs. of 12 variables: $ PassengerId: int 1 2 3 4 5 6 7 8 9 10 ... $ Survived : int 0 1 1 1 0 0 0 0 1 1 ... $ Pclass : int 3 1 3 1 3 3 1 3 3 2 ... $ Name : chr "Braund, Mr. Owen Harris" "Cumings, Mrs. John Bradley (Florence Briggs Thayer)" "Heikkinen, Miss. Laina" "Futrelle, Mrs. Jacques Heath (Lily May Peel)" ... $ Sex : chr "male" "female" "female" "female" ... $ Age : num 22 38 26 35 35 NA 54 2 27 14 ... $ SibSp : int 1 1 0 1 0 0 0 3 0 1 ... $ Parch : int 0 0 0 0 0 0 0 1 2 0 ... $ Ticket : chr "A/5 21171" "PC 17599" "STON/O2. 3101282" "113803" ... $ Fare : num 7.25 71.28 7.92 53.1 8.05 ... $ Cabin : chr NA "C85" NA "C123" ... $ Embarked : chr "S" "C" "S" "S" ... 

training[training==""] <- NA
a <- apply(training,2,is.na) summary(a) PassengerId Survived Pclass Name Sex

Mode :logical Mode :logical Mode :logical Mode :logical Mode :logical
FALSE:891 FALSE:891 FALSE:891 FALSE:891 FALSE:891
Age            SibSp           Parch           Ticket           Fare        
Mode :logical Mode :logical Mode :logical Mode :logical Mode :logical
FALSE:714 FALSE:891 FALSE:891 FALSE:891 FALSE:891
TRUE :177

Cabin Embarked
Mode :logical Mode :logical
FALSE:204 FALSE:889
TRUE :687 TRUE :2
apply(a,2,sum) PassengerId Survived Pclass Name Sex Age SibSp 0 0 0 0 0 177 0 Parch Ticket Fare Cabin Embarked 0 0 0 687 2
It can be seen that Age,Cabin and Embarked variables have missing values. Cabin has most number of missing values.These missing values can be found by using ‘Multivariate Imputation by Chained Equations (MICE)’ package training$Salutation <- gsub('(., )|(\..)', '',training$Name)

table(training$Sex,training$Salutation)

Capt Col Don  Dr Jonkheer Lady Major Master Miss Mlle Mme  Mr Mrs  Ms Rev Sir
female 0 0 0 1 0 1 0 0 182 2 1 0 125 1 0 0 male 1 2 1 6 1 0 2 40 0 0 0 517 0 0 6 1
     the Countess
female 1 male 0 

misc <- c("Capt","Col","Don","Dr","Jonkheer","Lady","Major","Rev","Sir","the Countess","Dona")
training$Salutation[training$Salutation == "Mlle"] <- "Miss" training$Salutation[training$Salutation == "Mme"] <- "Miss" training$Salutation[training$Salutation %in% misc] <- "Misc" table(training$Sex,training$Salutation)
     Master Misc Miss  Mr Mrs  Ms
female 0 3 185 0 125 1 male 40 20 0 517 0 0 training$Surname <- sapply(training$Name,function(x) strsplit(x, split = '[,.]')[[1]][1])
s <- nlevels(factor(training$Surname)) paste('We have', s, 'unique surnames in the training dataset amongst',nrow(training), 'passangers.') [1] "We have 667 unique surnames in the training dataset amongst 891 passangers."
training$Deck <- substr(training$Cabin,1,1)
paste("Titanic has", nlevels(factor(training$Deck)),"decks on the ship.") [1] "Titanic has 8 decks on the ship."
$ Family : Factor w/ 875 levels "Abbing - ","Abbott - ",..: 101 183 335 273 16 544 506 614 388 565 ... set.seed(6)
imp = mice(training, method = "rf", m=5)
iter imp variable 1 1 Age 1 2 Age 1 3 Age 1 4 Age 1 5 Age 2 1 Age 2 2 Age 2 3 Age 2 4 Age 2 5 Age 3 1 Age 3 2 Age 3 3 Age 3 4 Age 3 5 Age 4 1 Age 4 2 Age 4 3 Age 4 4 Age 4 5 Age 5 1 Age 5 2 Age 5 3 Age 5 4 Age 5 5 Age Warning message: Number of logged events: 8 imputedtraining = complete(imp)
summary(imp) Class: mids Number of multiple imputations: 5 Imputation methods: PassengerId Survived Pclass Name Sex Age SibSp "" "" "" "" "" "rf" "" Parch Ticket Fare Cabin Embarked Salutation Surname "" "" "" "" "" "" "" Deck "" PredictorMatrix: PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked PassengerId 0 1 1 0 0 1 1 1 0 1 0 0 Survived 1 0 1 0 0 1 1 1 0 1 0 0 Pclass 1 1 0 0 0 1 1 1 0 1 0 0 Name 1 1 1 0 0 1 1 1 0 1 0 0 Sex 1 1 1 0 0 1 1 1 0 1 0 0 Age 1 1 1 0 0 0 1 1 0 1 0 0 Salutation Surname Deck PassengerId 0 0 0 Survived 0 0 0 Pclass 0 0 0 Name 0 0 0 Sex 0 0 0 Age 0 0 0 Number of logged events: 8 it im dep meth out 1 0 0 constant Name 2 0 0 constant Sex 3 0 0 constant Ticket 4 0 0 constant Cabin 5 0 0 constant Embarked 6 0 0 constant Salutation apply(apply(imputedtraining,2,is.na),2,sum) PassengerId Survived Pclass Name Sex Age SibSp 0 0 0 0 0 0 0 Parch Ticket Fare Cabin Embarked Salutation Surname 0 0 0 687 2 0 0 Deck 687
par(mfrow=c(1,2))
hist(training$Age, main = "Before Imputation", col = "violet") hist(imputedtraining$Age, main = "Post Imputation", col = "blue")
par(mfrow=c(1,2))
hist(training$Fare, main = "Before Imputation", col = "violet") hist(imputedtraining$Fare, main = "Post Imputation", col = "blue")
#Missing cases (numbers): map_int(train.raw,~sum(is.na(.x)))
Survived Pclass Name Sex Age SibSp Parch Ticket
0 0 0 0 117 0 0 0
Fare Cabin Embarked
0 478 2
Cabin has a large number of missing values (77% missing). Imputing this variable may prove challenging or even useless. Age (19.9% missing) and Embarked (0.2%) missing


